{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9468346a339477c8ef2e6d575223502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_803de9b68208413987ca968a80430a4d",
              "IPY_MODEL_0d739a48093e43aa91b987b43b6311ee",
              "IPY_MODEL_4e0892a7448a4fb68edc0173320b8f27"
            ],
            "layout": "IPY_MODEL_2b191324b98a414d80f6fd71bb3f17b5"
          }
        },
        "803de9b68208413987ca968a80430a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7790ab1f085245ca970b6588498c52ec",
            "placeholder": "​",
            "style": "IPY_MODEL_301834a44e2d49d294ff10c5f53152ed",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0d739a48093e43aa91b987b43b6311ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_672c879e51bd4b1288972c690d9daf76",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fa3a7c581c54311b5141ff4f240fabd",
            "value": 28
          }
        },
        "4e0892a7448a4fb68edc0173320b8f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5809331b3090428a869a1ecd45e1a9f7",
            "placeholder": "​",
            "style": "IPY_MODEL_adf02a58ce844cb89ada15ebfe9c6afc",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.30kB/s]"
          }
        },
        "2b191324b98a414d80f6fd71bb3f17b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7790ab1f085245ca970b6588498c52ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301834a44e2d49d294ff10c5f53152ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "672c879e51bd4b1288972c690d9daf76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa3a7c581c54311b5141ff4f240fabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5809331b3090428a869a1ecd45e1a9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf02a58ce844cb89ada15ebfe9c6afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf46fa78e8124ca6ba349edecb767dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb75b54f0a6d48abac0905ae35ee7b08",
              "IPY_MODEL_8efc856ffaf64890acedc962de6d6652",
              "IPY_MODEL_fd6407ef80e3476db67a463cdb655ab3"
            ],
            "layout": "IPY_MODEL_d60eff8b7c6d4ff1b95edbcf01f1338a"
          }
        },
        "eb75b54f0a6d48abac0905ae35ee7b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d376f128fb9041ec9c449bbfc3c32837",
            "placeholder": "​",
            "style": "IPY_MODEL_d149ff8473934a978590346ac32b8981",
            "value": "config.json: 100%"
          }
        },
        "8efc856ffaf64890acedc962de6d6652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ea7f817a524ab2a42f5e60223422fd",
            "max": 1496,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f38f4a15ece48fd9124252f48636c9b",
            "value": 1496
          }
        },
        "fd6407ef80e3476db67a463cdb655ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8ffa6fdd25a4fd195bfead0994873b5",
            "placeholder": "​",
            "style": "IPY_MODEL_0b7abacb1156462488617732342aa00f",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 99.9kB/s]"
          }
        },
        "d60eff8b7c6d4ff1b95edbcf01f1338a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d376f128fb9041ec9c449bbfc3c32837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d149ff8473934a978590346ac32b8981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00ea7f817a524ab2a42f5e60223422fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f38f4a15ece48fd9124252f48636c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8ffa6fdd25a4fd195bfead0994873b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b7abacb1156462488617732342aa00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c402937cc384ed893e39da40bf085cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a8205b2dbf64b25afbfa4e4725e2636",
              "IPY_MODEL_2a120699133742aea267ad6077819f8b",
              "IPY_MODEL_ebe837802d4f409ca81a72d0334c0eae"
            ],
            "layout": "IPY_MODEL_5c342b3d220f4be2b2c29bc65d4da8e8"
          }
        },
        "6a8205b2dbf64b25afbfa4e4725e2636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758a10d02b584417bab06d88a290e0e0",
            "placeholder": "​",
            "style": "IPY_MODEL_1ebe0a7353464bb1810be641cfc3c84d",
            "value": "vocab.json: 100%"
          }
        },
        "2a120699133742aea267ad6077819f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46bde9b5329441c19dd7c1edf2782777",
            "max": 1561415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d49b64df47d340438d9cad22e021402f",
            "value": 1561415
          }
        },
        "ebe837802d4f409ca81a72d0334c0eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b67eabb5ef74a25a65a3b0aaefd9bc4",
            "placeholder": "​",
            "style": "IPY_MODEL_ff1300c06d7f47b48b690afad03e9a79",
            "value": " 1.56M/1.56M [00:00&lt;00:00, 3.14MB/s]"
          }
        },
        "5c342b3d220f4be2b2c29bc65d4da8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758a10d02b584417bab06d88a290e0e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ebe0a7353464bb1810be641cfc3c84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46bde9b5329441c19dd7c1edf2782777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49b64df47d340438d9cad22e021402f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b67eabb5ef74a25a65a3b0aaefd9bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1300c06d7f47b48b690afad03e9a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c5adcd0ad9408b9ad5161eed3f674e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09abb999fba0422c9713699bfbba46eb",
              "IPY_MODEL_2522e363ca1440069de21473b6162362",
              "IPY_MODEL_912d0db5c365407fbb8abf16aba14025"
            ],
            "layout": "IPY_MODEL_0e9b2c7abbe14d7abb72819592f00823"
          }
        },
        "09abb999fba0422c9713699bfbba46eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53891458c04845c4aad5589bf0f8d0b2",
            "placeholder": "​",
            "style": "IPY_MODEL_46b2e2b9f0cc460c8d222080750979f2",
            "value": "merges.txt: 100%"
          }
        },
        "2522e363ca1440069de21473b6162362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b4cbf70616488cafe289e724db323c",
            "max": 895731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ac94bab50ee4a2997942c19c0ce3471",
            "value": 895731
          }
        },
        "912d0db5c365407fbb8abf16aba14025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acf01d54751540619e7bbec588eef92e",
            "placeholder": "​",
            "style": "IPY_MODEL_ea8da5275aa748cc82601016d71cef48",
            "value": " 896k/896k [00:00&lt;00:00, 6.03MB/s]"
          }
        },
        "0e9b2c7abbe14d7abb72819592f00823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53891458c04845c4aad5589bf0f8d0b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b2e2b9f0cc460c8d222080750979f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39b4cbf70616488cafe289e724db323c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac94bab50ee4a2997942c19c0ce3471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acf01d54751540619e7bbec588eef92e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8da5275aa748cc82601016d71cef48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa4389f8c02b42c087aa1060fade3f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3a3be4ce1d64716aed601ba8cb0002c",
              "IPY_MODEL_1dfb9d22b1e94e0b8420ca67fd6380d3",
              "IPY_MODEL_d5294b5e8709463fa3e0e5b1ec6aadf1"
            ],
            "layout": "IPY_MODEL_492cb62175564627a682ff69f9dced1f"
          }
        },
        "e3a3be4ce1d64716aed601ba8cb0002c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e27e78f584ba434eb8bea09936ae2772",
            "placeholder": "​",
            "style": "IPY_MODEL_6744227ef446442a9466d8f357b1ac16",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1dfb9d22b1e94e0b8420ca67fd6380d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6df5ce0619b14168aab8b840f2c6e62c",
            "max": 553238687,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86448c0987a34d47b14e6c33956b6c23",
            "value": 553238687
          }
        },
        "d5294b5e8709463fa3e0e5b1ec6aadf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e387904eabd046899924f20cf047a981",
            "placeholder": "​",
            "style": "IPY_MODEL_1fea15a8e802439ab8ce4d797974273f",
            "value": " 553M/553M [00:17&lt;00:00, 38.2MB/s]"
          }
        },
        "492cb62175564627a682ff69f9dced1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27e78f584ba434eb8bea09936ae2772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6744227ef446442a9466d8f357b1ac16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6df5ce0619b14168aab8b840f2c6e62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86448c0987a34d47b14e6c33956b6c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e387904eabd046899924f20cf047a981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fea15a8e802439ab8ce4d797974273f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### He HUANG / LI M2/ 22107447"
      ],
      "metadata": {
        "id": "NAS3z-aD1OoX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADMDWc5LgpC0"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# WSD by fine-tuning a transformer-based pre-trained model\n",
        "\n",
        "**Copy this notebook (File>Save a copy in Drive)**\n",
        "\n",
        "**Add your name in notebook's name**\n",
        "\n",
        "**Deadlines**\n",
        "- send me a shared link by email with subject \"ML3 finetuning for WSD + last NAME + NAME\", before **Dec 27**\n",
        "- don't forget to give me **edit rights**\n",
        "- the execution traces should be visible\n",
        "- **Strong advice**:\n",
        "  - do the TODO1 and TODO2 by next lab session (Dec 8)\n",
        "  - freeze the FlauBERT's parameters in your preliminary experiments AND check you did it right\n",
        "  - don't forget to enable the use of a gpu on colab:\n",
        "  - Runtime > Change runtime type > Hardware accelerator => select \"T4 GPU\", which is enough\n",
        "  - Exécution > Modifier le type d'exécution > Accélérateur matériel > T4 GPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUrBv8Gvg2bE"
      },
      "source": [
        "We will use the French FrameNet \"[ASFALDA](http://asfalda.linguist.univ-paris-diderot.fr/frameIndex.xml)\" dataset to experiment the Word Sense Disambiguation task (WSD).\n",
        "\n",
        "In this dataset, some words have been manually associated with a semantic frame:\n",
        "- these words are called the **\"targets\"**\n",
        "- find the correct frame for a given word token corresponds to a word sense disambiguation task **(WSD)**\n",
        "- note though that a single frame pertains to several lexical units (e.g. FR_Commerce_buy => acheter.v, achat.n, acquérir.v, etc...)\n",
        "- for this lab session, sentences containing several targets have been duplicated: each line corresponds to a (sentence, target) pair.\n",
        "\n",
        "FrameNet data also contains annotations for the semantic roles of semantic arguments (Buyer, Seller, Goods ...), which will be ignored for this lab session.\n",
        "\n",
        "So, the objective of this lab is to build a classifier:\n",
        "- input = a (sentence, target) pair\n",
        "- output = a probability distribution over the various \"senses\" (namely frames)\n",
        "  - in basic version, we do not impose that a given target be only associated with its possible senses (namely those that were seen in the training data for this target lemma).\n",
        "\n",
        "A central trait of our classifier will be to use the contextual representation of the target, as output by a transformer-based pre-trained language model.\n",
        "\n",
        "Note that *BERT*-like models provide vectors for tokens, each token being potentially a subword.\n",
        "**In your base version, you will use the FlauBERT vector of the FIRST token of the target word.**\n",
        "\n",
        "Example: for the target *comprenions* in:\n",
        "\n",
        "*Nous comprenions bien le cours*\n",
        "\n",
        "tokenized as :\n",
        "\n",
        "'\\<s>', 'Nous\\</w>', 'compren', 'ions\\</w>', 'bien\\</w>', 'le\\</w>', 'cours\\</w>', '.\\</w>, '\\</s>'\n",
        "\n",
        "you will use the last hidden vector of \"compren\".\n",
        "\n",
        "The base classifier will be a neural network comprising\n",
        "- the pre-trained language model\n",
        "- which provides the hidden vector of the 1st token of the target word\n",
        "- plus a simple linear layer + softmax into the set of frames seen in the training set.\n",
        "\n",
        "We have a single classifier for all lemmas. In the base version, we put no constraint on which frames can be associated with a given target-lemma.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp3IN9YQexxx"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm # for progress bars in notebooks\n",
        "from random import shuffle\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_c3C5Pzexx-"
      },
      "source": [
        "## Naming conventions\n",
        "\n",
        "- sentences are already segmented into words (with a rule-based tokenizer)\n",
        "- but are not segmented into subwords yet\n",
        "- we use \"word\" or \"w\" for the tokens obtained after pre-segmentation\n",
        "- and \"token\" for units obtained after *BERT*-like tokenization (BPE ou WordPiece etc...)\n",
        "\n",
        "- in variable names, we distinguish\n",
        " - integer identifiers for symbols\n",
        "   (for the token vocabulary, the frame vocabulary ...)\n",
        " - versus the rank of a unit (either word or token) within a sequence\n",
        "- tid => token identifier\n",
        "- wrk => rank of a word in a the pre-tokenized sequence\n",
        "- trk => rank of a token in a bert*-tokenized sequence\n",
        "- tg => \"target\", so\n",
        " - tg_wrk = rank of the target word\n",
        " - tg_trk = rank of the first token of the target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvqLZ8HGR-GT"
      },
      "source": [
        "## Get a variable for the device (CPU or GPU)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1clXe8e2SBta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b253273d-a9cc-4dc6-910b-d747ac0d1d54"
      },
      "source": [
        "# in order to use a GPU\n",
        "# modify notebook settings:\n",
        "# Runtime > Change runtime type > Hardware accelerator => select \"T4 GPU\", which is enough\n",
        "\n",
        "# if a GPU is available, we will use it\n",
        "if torch.cuda.is_available():\n",
        "    # object torch.device\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    device_id = torch.cuda.current_device()\n",
        "    gpu_properties = torch.cuda.get_device_properties(device_id)\n",
        "    print(\"We will use GPU %d (%s) of compute capability %d.%d with \"\n",
        "          \"%.2fGb total memory.\\n\" %\n",
        "          (device_id,\n",
        "          gpu_properties.name,\n",
        "          gpu_properties.major,\n",
        "          gpu_properties.minor,\n",
        "          gpu_properties.total_memory / 1e9))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use GPU 0 (Tesla T4) of compute capability 7.5 with 15.84Gb total memory.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "rFZ9-ZKrIl68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfm0CXb9exyF"
      },
      "source": [
        "## \"ASFALDA\" dataset\n",
        "\n",
        "A French FrameNet, comprising about 16000 annotated targets, into about 100 distinct frames, along with their semantic role annotations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kySX0ye3jdpP"
      },
      "source": [
        "### Fetching the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRkusCSCjg8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f082930-0e2b-4508-f285-048b517f96d5"
      },
      "source": [
        "if not os.path.exists('./asfalda_data_for_wsd/'):\n",
        "  # shell commands can be run using !\n",
        "  !pip install wget\n",
        "  import wget\n",
        "\n",
        "  # The URL for the dataset zip file.\n",
        "  url = 'http://www.linguist.univ-paris-diderot.fr/~mcandito/divers/asfalda_data_for_wsd.tgz'\n",
        "\n",
        "\n",
        "  if not os.path.exists('./asfalda_data_for_wsd.tgz'):\n",
        "    print('Downloading dataset')\n",
        "    wget.download(url, './asfalda_data_for_wsd.tgz')\n",
        "    !tar zxf asfalda_data_for_wsd.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=f9b9fa143e12d7204c5a721e38524ad9ca63e761ef8e6c1aece1c0417031429d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Downloading dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_2cjFvYfOn3"
      },
      "source": [
        "### Data loading method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQhZaBzexyF"
      },
      "source": [
        "def load_asfalda_data(gold_data_file, split_info_file):\n",
        "    \"\"\"\n",
        "        Inputs: - asfalda gold data file\n",
        "                - file indicating the corpus type for each sentence id\n",
        "\n",
        "        Returns 4 dictionaries (whose keys are corpus types (train/dev/test))\n",
        "        - sentences = list of sentences, each sent is a list of words\n",
        "        - list of rank of target word in each sentence\n",
        "        - list of target lemmas\n",
        "        - gold labels\n",
        "\n",
        "        Example:\n",
        "        sentences['train'] = [[ ]]\n",
        "         # the targets are the 3rd and first words\n",
        "        tg_wrks['train'] = [2, 0]\n",
        "        tg_lemmas['train'] = ['comprendre', 'comprendre']\n",
        "        labels['train'] = ['frame1', 'frame2']\n",
        "\n",
        "    \"\"\"\n",
        "    # load the usual split into train / dev / test\n",
        "    s = open(split_info_file)\n",
        "    lines = [ l[:-1].split('\\t') for l in s.readlines() ]\n",
        "    split_info_dic = { line[0]:line[1] for line in lines }\n",
        "\n",
        "    # dev / train / test sentences\n",
        "    sentences = {'dev':[], 'train':[], 'test':[]}\n",
        "    # the word ranks (wrk) for the target words\n",
        "    tg_wrks = {'dev':[], 'train':[], 'test':[]}\n",
        "    # target lemmas\n",
        "    tg_lemmas = {'dev':[], 'train':[], 'test':[]}\n",
        "    # the labels of targets (= frames)\n",
        "    labels = {'dev':[], 'train':[], 'test':[]}\n",
        "\n",
        "    max_sent_len = {'dev':0, 'train':0, 'test':0}\n",
        "    max_tg_wrk = {'dev':0, 'train':0, 'test':0}\n",
        "\n",
        "    stream = open(gold_data_file)\n",
        "    for line in stream.readlines():\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        line = line.strip()\n",
        "        (sentid, tg_wrk, frame_name, tg_lemma, tg_pos, rest) = line.split('\\t',5)\n",
        "        # role annotation is ignored\n",
        "        # sentences are pre-segmented into space-separated words\n",
        "        # => we split on space, and will use the is_split_into_words=True mode of the FlauBERT tokenizer\n",
        "        sentence = rest.split(\"\\t\")[-1].split(' ')\n",
        "        part = split_info_dic[sentid]\n",
        "        tg_wrk = int(tg_wrk)\n",
        "\n",
        "        l = len(sentence)\n",
        "        sentences[part].append(sentence)\n",
        "        labels[part].append(frame_name)\n",
        "        tg_wrks[part].append(tg_wrk)\n",
        "        tg_lemmas[part].append(tg_lemma)\n",
        "        if max_sent_len[part] < l:\n",
        "            max_sent_len[part] = l\n",
        "        if max_tg_wrk[part] < tg_wrk:\n",
        "            max_tg_wrk[part] = tg_wrk\n",
        "    print(\"Max sentence length:\", max_sent_len)\n",
        "    print(\"Max target rank (in words):\", max_tg_wrk)\n",
        "\n",
        "    return sentences, tg_wrks, tg_lemmas, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo-B32y4c308"
      },
      "source": [
        "### Data loading and defining ids for labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaKnFVJ0exyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4ad07a-d75a-4312-83a1-18c6df5da748"
      },
      "source": [
        "gold_data_file = './asfalda_data_for_wsd/sequoiaftb.asfalda_1_3.gold.uniq.nofullant.txt'\n",
        "\n",
        "# usual split train / dev / test for this corpus\n",
        "split_info_file = './asfalda_data_for_wsd/sequoiaftb_split_info'\n",
        "\n",
        "sentences, tg_wrks, tg_lemmas, label_strs = load_asfalda_data(gold_data_file,\n",
        "                                                              split_info_file)\n",
        "\n",
        "for p in sentences.keys():\n",
        "    avgl = sum([len(s) for s in sentences[p]])/len(sentences[p])\n",
        "    print(\"%s : %d sentences, average lentgh=%3.2f\"\n",
        "          %(p, len(sentences[p]), avgl))\n",
        "\n",
        "# creating label ids for frames seen in training set\n",
        "i2label = list(set(label_strs['train']))\n",
        "# id for unknown frame (for dev and test)\n",
        "i2label.append('*UNK*')\n",
        "\n",
        "label2i = {x:i for i,x in enumerate(i2label)}\n",
        "# id of special frame \"Other_sense\"\n",
        "i_OTHER_SENSE = label2i['Other_sense']\n",
        "\n",
        "# sequence of gold labels\n",
        "# for each sub-corpus (key = dev/train/test)\n",
        "labels = {}\n",
        "for p in label_strs.keys():\n",
        "    labels[p] = [label2i[x] if x in label2i else label2i['*UNK*'] for x in label_strs[p]]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length: {'dev': 115, 'train': 271, 'test': 140}\n",
            "Max target rank (in words): {'dev': 96, 'train': 267, 'test': 115}\n",
            "dev : 2688 sentences, average lentgh=38.03\n",
            "train : 18657 sentences, average lentgh=38.99\n",
            "test : 3447 sentences, average lentgh=38.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Rgiftb-CQ5"
      },
      "source": [
        "### TODO1 : MFS Baseline (\"most frequent sense\")\n",
        "\n",
        "In WSD, a very strong baseline is to always assign the most frequent sense of a word, independently of its context.\n",
        "\n",
        "Note this is a supervised baseline, since we need a sense-annotated corpus to compute the most frequent sense of each word.\n",
        "\n",
        "- Compute the most frequent sense of each **target-lemma**\n",
        "  (using counts found in **train**)\n",
        "\n",
        "- and compute the MFS baseline, namely the accuracy obtained when choosing the most frequent sense of each target\n",
        "  - MFS in train\n",
        "  - MFS in dev (always using frequencies in train to get the most frequent senses)\n",
        "    - **NB**: in case of unknown target lemma, fall back on the most frequent frame in full training data\n",
        "\n",
        "- Study the items in dev that are unknown in train:\n",
        "  - unknown target lemmas\n",
        "  - unknown frame / target-lemma associations\n",
        "  - unknown frames\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2f7R9YD9_OH"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe for each sub-corpus\n",
        "train_part = pd.DataFrame({'tg_lemma' : tg_lemmas['train'],\n",
        "                           'label' : label_strs['train']})\n",
        "dev_part = pd.DataFrame({'tg_lemma' : tg_lemmas['dev'],\n",
        "                         'label' : label_strs['dev']})\n",
        "test_part = pd.DataFrame({'tg_lemma' : tg_lemmas['test'],\n",
        "                          'label' : label_strs['test']})"
      ],
      "metadata": {
        "id": "4RCd_dKw9i5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the frequency of each lemma associated with each label\n",
        "MSF_train = train_part.groupby(['tg_lemma', 'label']).size().reset_index(name='frequency')"
      ],
      "metadata": {
        "id": "KsrX01qkAaMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the label with the highest frequency for each lemma in the train set\n",
        "most_freq_train = MSF_train.groupby('tg_lemma').apply(lambda x: x.nlargest(1, 'frequency')).reset_index(drop=True)\n",
        "most_freq_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "GhDBcYmSJ-mK",
        "outputId": "a628580f-fa25-4605-8047-0370ee56ac86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tg_lemma                               label  frequency\n",
              "0             aborder                   FR_Speak_on_topic         11\n",
              "1             aboutir                           Causation         24\n",
              "2       aboutissement                         Other_sense          4\n",
              "3           accentuer  FR_Contingency-Objective_influence          7\n",
              "4         acceptation                     FR_Taking_sides          4\n",
              "..                ...                                 ...        ...\n",
              "911            éviter                          Preventing         49\n",
              "912         évocation                   FR_Speak_on_topic          1\n",
              "913           évoquer                   FR_Speak_on_topic         45\n",
              "914    être_ce_à_dire                         Other_sense          2\n",
              "915  être_fonction_de  FR_Contingency-Objective_influence          1\n",
              "\n",
              "[916 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0172be0-2c03-42eb-bb3f-85bbe7b42958\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tg_lemma</th>\n",
              "      <th>label</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aborder</td>\n",
              "      <td>FR_Speak_on_topic</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aboutir</td>\n",
              "      <td>Causation</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aboutissement</td>\n",
              "      <td>Other_sense</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>accentuer</td>\n",
              "      <td>FR_Contingency-Objective_influence</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acceptation</td>\n",
              "      <td>FR_Taking_sides</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>éviter</td>\n",
              "      <td>Preventing</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>évocation</td>\n",
              "      <td>FR_Speak_on_topic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>évoquer</td>\n",
              "      <td>FR_Speak_on_topic</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>914</th>\n",
              "      <td>être_ce_à_dire</td>\n",
              "      <td>Other_sense</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>être_fonction_de</td>\n",
              "      <td>FR_Contingency-Objective_influence</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>916 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0172be0-2c03-42eb-bb3f-85bbe7b42958')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0172be0-2c03-42eb-bb3f-85bbe7b42958 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0172be0-2c03-42eb-bb3f-85bbe7b42958');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9489b613-61be-41fe-b939-3d16a6fff5b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9489b613-61be-41fe-b939-3d16a6fff5b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9489b613-61be-41fe-b939-3d16a6fff5b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the most frequency frame in train set\n",
        "most_sense_train = MSF_train['label'].value_counts().idxmax()\n",
        "print(\"The most frequent frame in train set :\", most_sense_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlNkjOU3J42L",
        "outputId": "55b858e7-7454-4262-f8a8-3e1ba75c0ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent frame in train set : Other_sense\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fall back on the most frequent frame in full training data\n",
        "MSF_default = {}\n",
        "dev_unknown = []\n",
        "\n",
        "for most_lemma, most_label in zip(most_freq_train['tg_lemma'], most_freq_train['label']):\n",
        "    MSF_default[most_lemma] = most_label\n",
        "\n",
        "for dev_lemma in dev_part['tg_lemma']:\n",
        "    check = MSF_default.get(dev_lemma)\n",
        "    if check is None:\n",
        "        dev_unknown.append(dev_lemma)\n",
        "        MSF_default[dev_lemma] = most_sense_train # fall back on the most frequent frame"
      ],
      "metadata": {
        "id": "CcWDADXrsXrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_unknown # the lemmas that are not seen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccGg_nSjTkKE",
        "outputId": "17f09b7f-945f-4ad2-fb37-4e418abf3af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['faire_ses_courses',\n",
              " 'donner_son_accord',\n",
              " 'déposition',\n",
              " 'faire_bloc',\n",
              " 'dans_cet_objectif',\n",
              " 'faire_référence',\n",
              " 'dénonciation',\n",
              " 'prendre_le_parti',\n",
              " 'se_rendre',\n",
              " 'sollicitation',\n",
              " 'admirer',\n",
              " 'relater',\n",
              " 'invalider',\n",
              " 'porter_parole',\n",
              " 'en_accord_avec',\n",
              " 'subodorer',\n",
              " 'consentement',\n",
              " 'flatter',\n",
              " 'fins',\n",
              " 'porter_à_à']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSF baseline in train set\n",
        "train_part['MSF'] = train_part['tg_lemma'].apply(lambda x: MSF_default[x])\n",
        "\n",
        "# Compute the accuracy\n",
        "(train_part['label'] == train_part['MSF']).sum() / train_part.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDtghNH0Dvhw",
        "outputId": "ab61ad30-8001-4288-a1f4-93beb086851d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8139572278501367"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSF baseline in dev set\n",
        "dev_part['MSF'] = dev_part['tg_lemma'].apply(lambda x: MSF_default[x])\n",
        "\n",
        "# Compute the accuracy\n",
        "(dev_part['label'] == dev_part['MSF']).sum() / dev_part.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH8SDPCbHILa",
        "outputId": "c46c3a1f-c371-47ba-ff7b-1e5095b7814d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7905505952380952"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Study the items in dev that are unknown in train\n",
        "# 1. unknown target lemmas\n",
        "dev_part[~dev_part['tg_lemma'].isin(train_part['tg_lemma'])].size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdMftRllUBRC",
        "outputId": "bacb523c-b065-4f40-de82-215b1219c052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. unknown frames\n",
        "dev_part[~dev_part['label'].isin(train_part['label'])].size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5fRiXHqVFJP",
        "outputId": "3b4c5b50-d932-45f0-986e-746f370cbb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. unknown lemmas and frames\n",
        "dev_ass = []\n",
        "train_ass = []\n",
        "\n",
        "for dev_lemma, dev_label in zip(dev_part['tg_lemma'], dev_part['label']):\n",
        "   dev_ass.append((dev_lemma, dev_label))\n",
        "for train_lemma, train_label in zip(train_part['tg_lemma'], train_part['label']):\n",
        "   train_ass.append((train_lemma, train_label))\n",
        "\n",
        "print(\"Unknown lemma with frame associations : \")\n",
        "\n",
        "for ass_dev in dev_ass:\n",
        "    if ass_dev not in train_ass:\n",
        "        print(ass_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L3fV6I-VIHq",
        "outputId": "8211ffa6-5f81-4586-d156-9d5c8293834a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unknown lemma with frame associations : \n",
            "('délibérer', 'FR_Chatting-Discussion')\n",
            "('dépenser', 'Other_sense')\n",
            "('faire_ses_courses', 'Commerce_buy')\n",
            "('opposition', 'Be_in_agreement_on_assessment')\n",
            "('donner_son_accord', 'FR_Grant_permission-Permitting')\n",
            "('déposition', 'FR_Speak_on_topic')\n",
            "('convier', 'Other_sense')\n",
            "('faire_bloc', 'Other_sense')\n",
            "('dans_cet_objectif', 'FR_Means_for_purpose')\n",
            "('confession', 'Other_sense')\n",
            "('délibérer', 'FR_Chatting-Discussion')\n",
            "('faire_référence', 'Other_sense')\n",
            "('opposé', 'FR_Being_in_favor_of')\n",
            "('dénonciation', 'Other_sense')\n",
            "('plaidoirie', 'FR_Attempt_suasion.legitimacy')\n",
            "('prendre_le_parti', 'FR_Deciding')\n",
            "('acceptation', 'Ratification')\n",
            "('se_rendre', 'Other_sense')\n",
            "('sollicitation', 'Other_sense')\n",
            "('admirer', 'Judgment')\n",
            "('relater', 'FR_Statement-manner-noise')\n",
            "('admirer', 'Judgment')\n",
            "('liquider', 'Other_sense')\n",
            "('invalider', 'Evidence')\n",
            "('porter_parole', 'Other_sense')\n",
            "('en_accord_avec', 'Be_in_agreement_on_action')\n",
            "('voir', 'FR_Awareness-Certainty-Opinion')\n",
            "('subodorer', 'FR_Awareness-Certainty-Opinion')\n",
            "('aviser', 'FR_Telling')\n",
            "('aviser', 'FR_Telling')\n",
            "('joindre', 'FR_Contacting')\n",
            "('dans_la_mesure_où', 'Other_sense')\n",
            "('accord', 'FR_Being_in_favor_of')\n",
            "('accord', 'FR_Being_in_favor_of')\n",
            "('consentement', 'FR_Grant_permission-Permitting')\n",
            "('en_accord_avec', 'Be_in_agreement_on_action')\n",
            "('faire_preuve', 'FR_Proving')\n",
            "('prononcer', 'Other_sense')\n",
            "('voir', 'FR_Reason')\n",
            "('en_raison_de', 'Other_sense')\n",
            "('confirmation', 'Other_sense')\n",
            "('louer', 'FR_Judgment_communication')\n",
            "('conversion', 'FR_Being_in_favor_of')\n",
            "('flatter', 'Judgment_direct_address')\n",
            "('opposé', 'Be_in_agreement_on_assessment')\n",
            "('fins', 'Other_sense')\n",
            "('porter_à_à', 'Other_sense')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE28jS8Jgqrz"
      },
      "source": [
        "## Data encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbOlFK9nLoU"
      },
      "source": [
        "### FlauBERT tokenization\n",
        "\n",
        "We use the FlauBERT model, using the Huggingface \"transformers\" module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4DfehySexyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b915ad-fa95-4c17-ec0b-52ea0336de9b"
      },
      "source": [
        "try:\n",
        "  import transformers\n",
        "except ImportError:\n",
        "  !pip install transformers\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "\n",
        "# flaubert's tokenization uses as first step a tokenization into words by moses\n",
        "try:\n",
        "  import sacremoses\n",
        "except ImportError:\n",
        "  !pip install sacremoses\n",
        "  import sacremoses\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJiKhfxhexyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "f9468346a339477c8ef2e6d575223502",
            "803de9b68208413987ca968a80430a4d",
            "0d739a48093e43aa91b987b43b6311ee",
            "4e0892a7448a4fb68edc0173320b8f27",
            "2b191324b98a414d80f6fd71bb3f17b5",
            "7790ab1f085245ca970b6588498c52ec",
            "301834a44e2d49d294ff10c5f53152ed",
            "672c879e51bd4b1288972c690d9daf76",
            "6fa3a7c581c54311b5141ff4f240fabd",
            "5809331b3090428a869a1ecd45e1a9f7",
            "adf02a58ce844cb89ada15ebfe9c6afc",
            "bf46fa78e8124ca6ba349edecb767dbb",
            "eb75b54f0a6d48abac0905ae35ee7b08",
            "8efc856ffaf64890acedc962de6d6652",
            "fd6407ef80e3476db67a463cdb655ab3",
            "d60eff8b7c6d4ff1b95edbcf01f1338a",
            "d376f128fb9041ec9c449bbfc3c32837",
            "d149ff8473934a978590346ac32b8981",
            "00ea7f817a524ab2a42f5e60223422fd",
            "2f38f4a15ece48fd9124252f48636c9b",
            "a8ffa6fdd25a4fd195bfead0994873b5",
            "0b7abacb1156462488617732342aa00f",
            "5c402937cc384ed893e39da40bf085cc",
            "6a8205b2dbf64b25afbfa4e4725e2636",
            "2a120699133742aea267ad6077819f8b",
            "ebe837802d4f409ca81a72d0334c0eae",
            "5c342b3d220f4be2b2c29bc65d4da8e8",
            "758a10d02b584417bab06d88a290e0e0",
            "1ebe0a7353464bb1810be641cfc3c84d",
            "46bde9b5329441c19dd7c1edf2782777",
            "d49b64df47d340438d9cad22e021402f",
            "3b67eabb5ef74a25a65a3b0aaefd9bc4",
            "ff1300c06d7f47b48b690afad03e9a79",
            "66c5adcd0ad9408b9ad5161eed3f674e",
            "09abb999fba0422c9713699bfbba46eb",
            "2522e363ca1440069de21473b6162362",
            "912d0db5c365407fbb8abf16aba14025",
            "0e9b2c7abbe14d7abb72819592f00823",
            "53891458c04845c4aad5589bf0f8d0b2",
            "46b2e2b9f0cc460c8d222080750979f2",
            "39b4cbf70616488cafe289e724db323c",
            "3ac94bab50ee4a2997942c19c0ce3471",
            "acf01d54751540619e7bbec588eef92e",
            "ea8da5275aa748cc82601016d71cef48"
          ]
        },
        "outputId": "9ba71d67-026e-4f07-bf42-1baf1af5f269"
      },
      "source": [
        "# We choose the FlauBERT model\n",
        "\n",
        "# we load tokenizer and config for now\n",
        "flaubert_tokenizer = AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "flaubert_config = AutoConfig.from_pretrained(\"flaubert/flaubert_base_cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9468346a339477c8ef2e6d575223502"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf46fa78e8124ca6ba349edecb767dbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.56M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c402937cc384ed893e39da40bf085cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/896k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66c5adcd0ad9408b9ad5161eed3f674e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMmtutNBexyQ"
      },
      "source": [
        "### TODO2: Encoding method\n",
        "\n",
        "The objective is to apply FlauBERT's tokenization, **keeping track of the position of the tokens of the targets**.\n",
        "\n",
        "Follow the instructions below to fill in the encode method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqvpr6ovexya"
      },
      "source": [
        "\n",
        "class WSDEncoder:\n",
        "    def __init__(self, tokenizer, config):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config # to get indices of special tokens\n",
        "\n",
        "\n",
        "    # TODO\n",
        "    #########################################################\n",
        "\n",
        "    def tokenize_word(self, word):\n",
        "        # Check if the word is start of an apostrophe contraction\n",
        "        if word.endswith(\"'\"):\n",
        "            return self.tokenizer.encode(word[:-1], add_special_tokens=False) + \\\n",
        "                self.tokenizer.encode(\"'\", add_special_tokens=False)\n",
        "        else:\n",
        "            # Regular tokenization\n",
        "            return self.tokenizer.encode(word, add_special_tokens=False)\n",
        "    #########################################################\n",
        "\n",
        "    def encode(self, sentences, tg_wrks, max_length=100, verbose=False, is_split_into_words=True):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - sentences : list of sentences\n",
        "           -- if is_split_into_words:\n",
        "              sentences are already split into words\n",
        "              (hence sentences = list of word strings [[w1, w2, w3], [w1, w2]...])\n",
        "           -- otherwise, sentences are to split on spaces to get words\n",
        "\n",
        "        - tg_wrks : list of the ranks of target words\n",
        "          (one rank per sentence, starting at 0 in a sentence)\n",
        "        - max_length : maximum length in number of tokens\n",
        "\n",
        "        Returns:\n",
        "        - tid_seqs : the sentences padded/truncated so that each contains max_length token ids\n",
        "        - first_trk_of_targets : for each sentence,\n",
        "                                 the rank in corresponding tid_seq\n",
        "                                 of the first token of the target word\n",
        "\n",
        "        Example with is_split_into_words=True: a batch with one sent\n",
        "        sentences = [ ['Conséquemment', ',', 'nous', 'comprendrions', '.'] ]\n",
        "        tg_wrks = [3]\n",
        "\n",
        "        if the sentence is tokenized into\n",
        "        '<s>', 'Con', 'séqu', 'emment</w>', ',</w>', 'nous</w>', 'compr', 'end', 'rions</w>', '.</w>' ....\n",
        "        the first token rank of the target \"comprendrions\" is 6 ('compr')\n",
        "\n",
        "        \"\"\"\n",
        "        # TODO HERE : encoding method\n",
        "\n",
        "        # Indications:\n",
        "        # 1. apply flaubert tokenization *word per word*, and build\n",
        "        #    tid_seqs first without padding / truncation nor special tokens,\n",
        "        #    and keep track of token rank of first token of target word\n",
        "        # 2. then truncate or pad, and add special symbols\n",
        "        # (write several methods for easier reading)\n",
        "\n",
        "        #  return tid_seqs, first_trk_of_targets\n",
        "\n",
        "      #########################################################\n",
        "        tid_seqs = []\n",
        "        first_trk_of_targets = []\n",
        "\n",
        "        for sent, tg_idx in zip(sentences, tg_wrks):\n",
        "            tokenized_sent = [self.config.bos_index]\n",
        "            target_lemma = sent[tg_idx]\n",
        "\n",
        "            for i, word in enumerate(sent):\n",
        "                tokenized_word = self.tokenize_word(word)\n",
        "                tokenized_sent.extend(tokenized_word)\n",
        "\n",
        "                # Check if the current word is the target word\n",
        "                if i == tg_idx:\n",
        "                  first_trk_of_targets.append(len(tokenized_sent) - len(tokenized_word))\n",
        "\n",
        "            sentence_word_ids = flaubert_tokenizer(' '.join(sent),add_special_tokens=True,max_length = max_length, truncation = True,padding = \"max_length\",pad_to_max_length = True)['input_ids']\n",
        "\n",
        "            tid_seqs.append(sentence_word_ids)\n",
        "\n",
        "        return tid_seqs, first_trk_of_targets\n",
        "      #########################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySTnpTLexyi"
      },
      "source": [
        "#### Encoding test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fK8CV5Bexyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4935d8e-b607-45cb-b588-1008a9fea385"
      },
      "source": [
        "encoder = WSDEncoder(flaubert_tokenizer, flaubert_config)\n",
        "\n",
        "# test encoder\n",
        "test_sents = [\"Conséquemment , nous comprendrions .\",\n",
        "              \"Le code comprend des erreurs .\",\n",
        "            \"J' essaie de comprendre les transformers .\",\n",
        "            \"Il n' a pas bien compris le code !\"]\n",
        "\n",
        "# we split into words (cf. asfalda dataset sentences are already split)\n",
        "test_sents = [ x.split(' ') for x in test_sents ]\n",
        "# target words are the occurrences of \"comprendre\"\n",
        "test_tg_wrks = [3, 2, 3, 5]\n",
        "max_length=10\n",
        "\n",
        "# TODO: uncomment to test your encode method\n",
        "tid_seqs, first_trk_of_targets = encoder.encode(test_sents, test_tg_wrks, max_length=10, verbose=True, is_split_into_words=True)\n",
        "\n",
        "for tid_seq, ft in zip(tid_seqs, first_trk_of_targets):\n",
        "    readable = flaubert_tokenizer.convert_ids_to_tokens(tid_seq)\n",
        "    print(\"Len = %d target token rank = %d tid_seq = %s (%s)\" % (len(tid_seq), ft, str(tid_seq), str(readable)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len = 10 target token rank = 6 tid_seq = [0, 1198, 17358, 13299, 14, 65, 18719, 1999, 19614, 1] (['<s>', 'Con', 'séqu', 'emment</w>', ',</w>', 'nous</w>', 'compr', 'end', 'rions</w>', '</s>'])\n",
            "Len = 10 target token rank = 3 tid_seq = [0, 55, 1138, 976, 23, 3842, 16, 1, 2, 2] (['<s>', 'Le</w>', 'code</w>', 'comprend</w>', 'des</w>', 'erreurs</w>', '.</w>', '</s>', '<pad>', '<pad>'])\n",
            "Len = 10 target token rank = 5 tid_seq = [0, 2684, 68, 5213, 15, 965, 22, 14659, 896, 1] (['<s>', 'J</w>', \"'</w>\", 'essaie</w>', 'de</w>', 'comprendre</w>', 'les</w>', 'transform', 'ers</w>', '</s>'])\n",
            "Len = 10 target token rank = 7 tid_seq = [0, 59, 261, 68, 34, 42, 83, 681, 20, 1] (['<s>', 'Il</w>', 'n</w>', \"'</w>\", 'a</w>', 'pas</w>', 'bien</w>', 'compris</w>', 'le</w>', '</s>'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHApJ8mgexyn"
      },
      "source": [
        "### TODO3: WSDData class: full encoding and batch production"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxpzaBhexyo"
      },
      "source": [
        "import random\n",
        "\n",
        "class WSDData:\n",
        "    def __init__(self, corpus_type, sentences, tg_wrks, tg_lemmas, labels, encoder, max_length=100):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - corpus type string (train/dev/test)\n",
        "        - list of sentences (each sentence = list of word strings)\n",
        "        - list of target word ranks : one per sentence\n",
        "        - list of gold label id\n",
        "        - encoder = instance of WSDEncoder\n",
        "\n",
        "        - max_length = size of encoded sequences, in nb of bert tokens\n",
        "                      (padded / truncated via encoder.encode)\n",
        "\n",
        "        Encodes all the data using the relevant identifiers\n",
        "        \"\"\"\n",
        "\n",
        "        self.corpus_type = corpus_type # train / dev / test / val\n",
        "        self.size = len(sentences)\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.labels = labels       # gold label ids\n",
        "        self.sentences = sentences # list of list of word strings\n",
        "        self.tg_lemmas = tg_lemmas\n",
        "        self.max_length = max_length\n",
        "\n",
        "        tid_seqs, tg_trks = encoder.encode(sentences, tg_wrks, self.max_length)\n",
        "\n",
        "        self.tid_seqs = tid_seqs  # sequences of token ids\n",
        "        self.tg_trks = tg_trks    # target token ranks\n",
        "\n",
        "\n",
        "    def shuffle(self):\n",
        "      \"\"\"\n",
        "      Rearranges all the data in a new random order\n",
        "      (sentences, tg_lemmas, tg_trks, tid_seqs, labels)\n",
        "\n",
        "      NB: ** original order might be lost **\n",
        "      \"\"\"\n",
        "      # TODO\n",
        "    #########################################################\n",
        "      data_zipped = list(zip(self.sentences, self.tg_lemmas, self.tg_trks, self.tid_seqs, self.labels))\n",
        "      random.shuffle(data_zipped)\n",
        "\n",
        "      return data_zipped\n",
        "    #########################################################\n",
        "\n",
        "    # production of a batch\n",
        "    def make_batches(self, batch_size, device, shuffle_data=False):\n",
        "        \"\"\"\n",
        "        Returns an iterator over 3 torch tensors\n",
        "        - batch of token id sequences\n",
        "        - corresponding batch of target token ranks\n",
        "        - corresponding batch of labels for these targets\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        # (Tip: use \"yield\" function to return an iterator)\n",
        "\n",
        "        # **NB** : the torch tensors can be directly sent to the right device\n",
        "        #          using .to(device)\n",
        "        # for ...\n",
        "        #    ...\n",
        "        #    yield(b_tid_seqs, b_tg_trks, b_labels)\n",
        "      #########################################################\n",
        "        if shuffle_data:\n",
        "            self.shuffle()\n",
        "\n",
        "        filtered_data = [(sent, lemma, trk, tid_seq, label)\n",
        "                          for sent, lemma, trk, tid_seq, label in zip(self.sentences, self.tg_lemmas, self.tg_trks, self.tid_seqs, self.labels) if trk < self.max_length - 2]\n",
        "\n",
        "        for i in range(0, len(filtered_data), batch_size):\n",
        "          # Extract data for the current batch\n",
        "          b_data = filtered_data[i:i + batch_size]\n",
        "\n",
        "          # Prepare the batch\n",
        "          b_tid_seqs = torch.tensor([d[3] for d in b_data], dtype=torch.long).to(device)\n",
        "          b_tg_trks = torch.tensor([d[2] for d in b_data], dtype=torch.long).to(device)\n",
        "          b_labels = torch.tensor([d[4] for d in b_data], dtype=torch.long).to(device)\n",
        "\n",
        "          # Yield the batch\n",
        "          yield (b_tid_seqs, b_tg_trks, b_labels)\n",
        "\n",
        "      #########################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding of the three sets train/dev/test\n",
        "MAX_LENGTH = 100\n",
        "wsd_data = {}\n",
        "# key = part of the split corpus (train/test/dev)\n",
        "for p in sentences.keys():\n",
        "    print(\"Encoding part %s ...\" % p)\n",
        "    wsd_data[p] = WSDData(p, sentences[p], tg_wrks[p], tg_lemmas[p], labels[p],\n",
        "                          encoder, max_length=MAX_LENGTH)\n",
        "    # we check that encoding provides the right lengths\n",
        "    for i, s in enumerate(wsd_data[p].tid_seqs):\n",
        "        if len(s) != MAX_LENGTH:\n",
        "            print(\"Size bug:\", i, s)\n"
      ],
      "metadata": {
        "id": "fiBeOrXqU718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd4e68a-ec9e-4863-86d2-1e8eb64392dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding part dev ...\n",
            "Encoding part train ...\n",
            "Encoding part test ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wsd_data['train'].sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_SQ02Dx71np",
        "outputId": "8408d6f4-48d0-44b1-975f-2aca46bf4c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cette',\n",
              " 'exposition',\n",
              " 'nous',\n",
              " 'apprend',\n",
              " 'que',\n",
              " 'dès',\n",
              " 'le',\n",
              " 'XIIe',\n",
              " 'siècle',\n",
              " ',',\n",
              " 'à',\n",
              " 'Dammarie-sur-Saulx',\n",
              " ',',\n",
              " 'entre',\n",
              " 'autres',\n",
              " 'sites',\n",
              " ',',\n",
              " 'une',\n",
              " 'industrie',\n",
              " 'métallurgique',\n",
              " 'existait',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIw1BE1wexys"
      },
      "source": [
        "## WSDClassifier class: the network for WSD\n",
        "\n",
        "Base architecture =\n",
        "- the FlauBERT model\n",
        "- plus linear layer + softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3_mEfGUe3yH"
      },
      "source": [
        "### TODO4: Digression: matrix operation\n",
        "\n",
        "Matrix operation to fetch the bert hidden vector of the first\n",
        "token of the targets.\n",
        "\n",
        "Input is\n",
        "1. x = a tensor for a batch of (truncated/padded) sentences\n",
        "   containing the bert vectors for all tokens of each sentence\n",
        "\n",
        "2. r = a tensor for the token ranks of the first token of the targets\n",
        "  \n",
        "=> we want to keep only the bert vectors of these first tokens\n",
        "\n",
        "TODO: write down the shapes of tensors x and r and of the output tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0DWembWfXtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e96cf0-5886-4c3d-fec0-ca273decb69a"
      },
      "source": [
        "x = torch.tensor([[[1, 2, 3, 4],\n",
        "                   [5, 6, 7, 8],\n",
        "                   [9, 10, 11, 12]],\n",
        "                  [[13, 14, 15, 16],\n",
        "                   [17, 18, 19, 20],\n",
        "                   [21, 22, 23, 24]]])\n",
        "print(x.shape)\n",
        "# if token ranks for the two sentences of the batch are (1,2)\n",
        "r = torch.tensor([1, 2])\n",
        "# => we want to get the [5, 6, 7, 8] and [21, 22, 23, 24] vectors\n",
        "\n",
        "# write down the matrix operation\n",
        "# see this source : https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "# o = ...\n",
        "o = x[torch.arange(x.size(0)), r]\n",
        "print(o)\n",
        "print(f\"The shape of the output is {o.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n",
            "tensor([[ 5,  6,  7,  8],\n",
            "        [21, 22, 23, 24]])\n",
            "The shape of the output is torch.Size([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ-w08okgaXv"
      },
      "source": [
        "### TODO5: The network : architecture, forward propagation, evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Vpgmjmkn88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aa4389f8c02b42c087aa1060fade3f45",
            "e3a3be4ce1d64716aed601ba8cb0002c",
            "1dfb9d22b1e94e0b8420ca67fd6380d3",
            "d5294b5e8709463fa3e0e5b1ec6aadf1",
            "492cb62175564627a682ff69f9dced1f",
            "e27e78f584ba434eb8bea09936ae2772",
            "6744227ef446442a9466d8f357b1ac16",
            "6df5ce0619b14168aab8b840f2c6e62c",
            "86448c0987a34d47b14e6c33956b6c23",
            "e387904eabd046899924f20cf047a981",
            "1fea15a8e802439ab8ce4d797974273f"
          ]
        },
        "outputId": "e908c09f-c331-4058-c61a-0ddb0539d8b5"
      },
      "source": [
        "flaubert_model = AutoModel.from_pretrained(\"flaubert/flaubert_base_cased\", return_dict=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/553M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa4389f8c02b42c087aa1060fade3f45"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flaubert_model.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApAPEqzUGq7o",
        "outputId": "cce52127-3301-4c5f-95f8-6ae3cbb58fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(68729, 768, padding_idx=2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFQEpfkRexyy"
      },
      "source": [
        "class WSDClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_labels, device, bert_model, bert_config, freeze_bert = True):\n",
        "        super(WSDClassifier, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # the full *BERT*-like model\n",
        "        # the .to(device) triggers the copy towards the relevant device\n",
        "        # (possibly a GPU)\n",
        "        self.bert_layer = bert_model\n",
        "        # config will allow to get the hidden vectors' size\n",
        "        self.bert_config = bert_config\n",
        "\n",
        "        #########################################################\n",
        "        # TODO HERE : rest of the network\n",
        "        input_dim = bert_config.hidden_size\n",
        "\n",
        "        self.linear_layer = nn.Linear(input_dim, num_labels)\n",
        "        self.softmax_layer = nn.LogSoftmax(dim=1)\n",
        "\n",
        "        # TODO: implement option to either freeze or fine-tune the BERT model\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        self.to(device)\n",
        "        #########################################################\n",
        "\n",
        "    def forward(self, b_tid_seq, b_tg_trk):\n",
        "        \"\"\"\n",
        "        Inputs: (all are tensors, on the relevant device)\n",
        "            - a batch of sentences = a batch of token id sequences\n",
        "              (as output in 'input_ids' member of tokenizer output)\n",
        "            - a batch of target token rank = for each of the sentences,\n",
        "              the rank of first token of the target word to disambiguate\n",
        "\n",
        "        Output: log_softmax scores for the whole batch (batch_size x num_labels)\n",
        "        \"\"\"\n",
        "        # TODO HERE\n",
        "        #  - get the *bert last hidden vectors for all the tokens of all the batch sentences\n",
        "        #    [ batch_size * seq_len * bert_emb_size ]\n",
        "\n",
        "        # Retrive only the last hidden state from BERT\n",
        "\n",
        "        #print(\"b_tid_seq.device\", b_tid_seq.device)\n",
        "        #print(\"b_tid_seq.shape\", b_tid_seq.shape)\n",
        "        output = self.bert_layer(b_tid_seq)[0]\n",
        "        #print(\"output.shape\", output.shape)\n",
        "        #  - isolate the vector of the (first) token of the target for all the batch sentences\n",
        "        #    [ batch_size * bert_emb_size ]\n",
        "\n",
        "        # Isolate the hidden state of the target token for each sentence in the batch\n",
        "        tgt_hidden_state = output[torch.arange(output.size(0)), b_tg_trk.long()]\n",
        "        #print(\"tgt_hidden_state.shape\", tgt_hidden_state.shape)\n",
        "\n",
        "        #    Tips to do this:\n",
        "        #    https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "        #\n",
        "        #  - and apply linear layer\n",
        "        # Pass through the classifier\n",
        "\n",
        "        linear_out = self.linear_layer(tgt_hidden_state)\n",
        "        log_softmax_scores = self.softmax_layer(linear_out)\n",
        "        return log_softmax_scores\n",
        "\n",
        "    def run_on_dataset(self, wsd_data, batch_size=32):\n",
        "        \"\"\"\n",
        "        Run classifier on wsd_data and compute accuracy\n",
        "        Inputs =\n",
        "         - wsd_data (WSDDataset instance)\n",
        "         - batch_size\n",
        "        Returns:\n",
        "         - list of predicted label ids\n",
        "        \"\"\"\n",
        "        pred_labels = []\n",
        "        gold_labels = []\n",
        "\n",
        "        # VERY IMPORTANT : toggle evaluation mode of the model (no dropout)\n",
        "        self.eval()\n",
        "\n",
        "        # TODO\n",
        "        with torch.no_grad():\n",
        "            for b_tid_seqs, b_tg_trks, b_labels in wsd_data.make_batches(batch_size, self.device):\n",
        "\n",
        "                scores = self.forward(b_tid_seqs, b_tg_trks)\n",
        "                preds = scores.argmax(dim=1)\n",
        "                pred_labels.append(preds)\n",
        "                gold_labels.append(b_labels)\n",
        "\n",
        "        return pred_labels, gold_labels\n",
        "\n",
        "    def evaluate(self, gold_labels, pred_labels):\n",
        "        \"\"\" returns accuracy, nb_correct, nb_total \"\"\"\n",
        "        # TODO\n",
        "        correct = sum(gold == pred for gold, pred in zip(gold_labels, pred_labels))\n",
        "        total = len(gold_labels)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrkbQ4hVexy1"
      },
      "source": [
        "# an instance of WSDClassifier\n",
        "num_labels = len(i2label)\n",
        "classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config)\n",
        "\n",
        "# uncomment to see the huge nb of parameters ...\n",
        "#for name, param in classifier.named_parameters():\n",
        "#    print(\"PARAM named %s, of shape %s\" % (name, str(param.shape)))\n",
        "#    print(param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LeXSxEXexy5"
      },
      "source": [
        "#### Test of forward propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4iIZvzDexy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a8906e-c46a-4e57-91e8-5108404862ae"
      },
      "source": [
        "# useless to compute gradients when testing\n",
        "with torch.no_grad():\n",
        "    # toggle train mode off\n",
        "    classifier.eval()\n",
        "    for b_tid_seqs, b_tg_trks, b_labels in wsd_data['dev'].make_batches(32, classifier.device, shuffle_data=True):\n",
        "\n",
        "        log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "        gold = b_labels[0] #.item()\n",
        "        print(\"GOLD LABEL of first ex %d ( = %s)\" % (gold, i2label[gold]))\n",
        "        print(\"LOG_PROBS before training: %s\\n\\n\" % str(log_probs[0]))\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOLD LABEL of first ex 11 ( = FR_Chatting-Discussion)\n",
            "LOG_PROBS before training: tensor([-4.5894, -4.4675, -4.0256, -5.1313, -6.0217, -4.9460, -4.6954, -5.8852,\n",
            "        -5.5249, -3.5971, -3.0743, -5.0495, -2.5728, -5.1314, -4.2159, -6.1469,\n",
            "        -6.3216, -4.6064, -5.8922, -4.6553, -3.8306, -5.3917, -5.0015, -4.5284,\n",
            "        -4.8239, -6.4730, -6.0997, -6.4645, -4.5307, -6.3986, -4.9323, -4.7071,\n",
            "        -5.5808, -5.6732, -4.8716, -4.7578, -4.2711, -4.8957, -3.5010, -5.3068,\n",
            "        -5.8354, -4.4243, -6.7641, -5.8209, -3.8994, -4.8649, -6.7769, -4.0813,\n",
            "        -5.2218, -3.5869, -5.4309, -3.9486, -4.4260, -4.8575, -4.8467, -5.8450,\n",
            "        -5.6314, -5.8245, -4.9561, -4.9771, -4.2732, -5.2863, -5.5016, -7.3731,\n",
            "        -5.3734, -6.4758, -4.2239, -3.8969, -3.0925, -4.8087, -4.8505, -5.5460,\n",
            "        -6.4659, -5.2382, -4.6858, -4.6569, -6.1225, -5.3833, -4.4674, -5.5865,\n",
            "        -4.0705, -4.9271, -5.1104, -6.6564, -6.1293, -4.3895, -3.4420, -5.7738,\n",
            "        -5.4490, -5.6875, -4.9133, -5.0933, -5.1418, -6.3049, -3.9182, -5.0080,\n",
            "        -5.5314, -5.1055, -6.9099, -4.8064, -4.5492, -4.8979, -4.9035, -4.9834,\n",
            "        -5.3647, -5.1297, -4.5258], device='cuda:0')\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aikfNi0zexy9"
      },
      "source": [
        "### TODO6: Training : fine-tuning for the WSD task\n",
        "\n",
        "**NB** full training on train data is **LONG**, so when developping your code, first try on a small part of the data.\n",
        "\n",
        "**NB** In general when using a *bert model in fine-tuning mode (not frozen), the needed learning rate tends to be lower"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(classifier, train_data, batch_size, optimizer, loss_function):\n",
        "    \"\"\"\n",
        "    Train classifier on a batch of data\n",
        "\n",
        "    Inputs:\n",
        "     - classifier\n",
        "     - train_data\n",
        "     - batch_size\n",
        "     - optimizer\n",
        "     - loss_function\n",
        "\n",
        "    Returns:\n",
        "     - avg_train_loss\n",
        "    \"\"\"\n",
        "    epoch_train_losses = []\n",
        "    classifier.train()\n",
        "\n",
        "    for b_tid_seqs, b_tg_trks, b_labels in train_data.make_batches(batch_size, classifier.device, shuffle_data=True):\n",
        "\n",
        "        classifier.zero_grad()\n",
        "\n",
        "        log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "        loss = loss_function(log_probs, b_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_train_losses.append(loss.item())\n",
        "\n",
        "    avg_train_loss = np.mean(epoch_train_losses)\n",
        "\n",
        "    return avg_train_loss\n"
      ],
      "metadata": {
        "id": "B58ujQMbiGnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_step(classifier, val_data, batch_size, optimizer, loss_function):\n",
        "    \"\"\"\n",
        "    Validate classifier on a batch of data\n",
        "\n",
        "    Inputs:\n",
        "     - classifier\n",
        "     - val_data\n",
        "     - batch_size\n",
        "     - optimizer\n",
        "     - loss_function\n",
        "\n",
        "    Returns:\n",
        "     - avg_val_loss\n",
        "     - accuracy\n",
        "    \"\"\"\n",
        "    epoch_val_losses = []\n",
        "    classifier.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for b_tid_seqs, b_tg_trks, b_labels in val_data.make_batches(BATCH_SIZE, DEVICE):\n",
        "\n",
        "            log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "            loss = loss_function(log_probs, b_labels)\n",
        "\n",
        "            epoch_val_losses.append(loss.item())\n",
        "            preds = log_probs.argmax(dim=1)\n",
        "            accuracy = classifier.evaluate(b_labels, preds)\n",
        "\n",
        "        avg_val_loss = np.mean(epoch_val_losses)\n",
        "\n",
        "    return avg_val_loss, accuracy"
      ],
      "metadata": {
        "id": "M8C6wJ6xjXF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOKrCRPFexy-"
      },
      "source": [
        "def training_loop(classifier, train_data, val_data, lr, batch_size, nb_epochs, patience, output_dir):\n",
        "    \"\"\"\n",
        "    Train classifier on train data for nb_epochs\n",
        "\n",
        "    Inputs:\n",
        "     - classifier\n",
        "     - train_data\n",
        "     - val_data\n",
        "     - lr\n",
        "     - batch_size\n",
        "     - nb_epochs\n",
        "     - patience\n",
        "     - output_dir\n",
        "\n",
        "    Returns:\n",
        "     - train_losses\n",
        "     - val_losses\n",
        "    \"\"\"\n",
        "\n",
        "    loss_function = nn.NLLLoss(reduction='mean')\n",
        "    # SGD is quicker (more convenient for debug phase)\n",
        "    #optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "    optimizer = optim.Adam(classifier.parameters(), lr=LR)\n",
        "\n",
        "    # losses at each epoch (on train / on validation set)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_acc = []\n",
        "    min_val_loss = None\n",
        "\n",
        "    epoch_id = 0\n",
        "\n",
        "    # Early stopping\n",
        "    patience_counter = 0\n",
        "\n",
        "    while epoch_id < nb_epochs:\n",
        "        # train\n",
        "        train_loss = training_step(classifier, train_data, batch_size, optimizer, loss_function)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # validate\n",
        "        val_loss, accuracy = validation_step(classifier, val_data, batch_size, optimizer, loss_function)\n",
        "        val_losses.append(val_loss)\n",
        "        val_acc.append(accuracy)\n",
        "\n",
        "        print(\"Epoch %d: train loss = %0.4f, val loss = %0.4f, val acc = %0.4f\" % (epoch_id, train_loss, val_loss, accuracy))\n",
        "\n",
        "        # Early stopping\n",
        "        if min_val_loss is None or val_loss < min_val_loss:\n",
        "            min_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch_id}\")\n",
        "                break\n",
        "\n",
        "        epoch_id += 1\n",
        "\n",
        "    return train_losses, val_losses, val_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = len(label2i)\n",
        "classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "NB_EPOCHS = 20\n",
        "PATIENCE = 2\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# to speed up during debug: train on dev\n",
        "#train_data = wsd_data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['dev']\n",
        "test_data = wsd_data['test']\n",
        "\n",
        "train_losses, val_losses, val_acc = training_loop(classifier, train_data, val_data, LR, BATCH_SIZE, NB_EPOCHS, PATIENCE, out_model_file) # train_losses, val_losses\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in train_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "print(\"val   acc: %s\" % ' / '.join([ \"%.4f\" % x for x in val_acc]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyB2brK_qVBu",
        "outputId": "ba999ca5-9a6f-4d61-a7e1-7e8d3319b23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss = 1.6249, val loss = 0.8076, val acc = 0.8214\n",
            "Epoch 1: train loss = 0.8164, val loss = 0.6323, val acc = 0.8571\n",
            "Epoch 2: train loss = 0.6740, val loss = 0.5743, val acc = 0.8214\n",
            "Epoch 3: train loss = 0.6175, val loss = 0.5559, val acc = 0.8571\n",
            "Epoch 4: train loss = 0.5926, val loss = 0.5432, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.5582, val loss = 0.5310, val acc = 0.8571\n",
            "Epoch 6: train loss = 0.5448, val loss = 0.5415, val acc = 0.8571\n",
            "Epoch 7: train loss = 0.5184, val loss = 0.5396, val acc = 0.8571\n",
            "Early stopping at epoch 7\n",
            "train losses: 1.6249 / 0.8164 / 0.6740 / 0.6175 / 0.5926 / 0.5582 / 0.5448 / 0.5184\n",
            "val   losses: 0.8076 / 0.6323 / 0.5743 / 0.5559 / 0.5432 / 0.5310 / 0.5415 / 0.5396\n",
            "val   acc: 0.8214 / 0.8571 / 0.8214 / 0.8571 / 0.8571 / 0.8571 / 0.8571 / 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters search\n",
        "batch_size = [32, 64, 128]\n",
        "lr = [0.00005, 0.001, 0.005]\n",
        "\n",
        "accuracy_list = []\n",
        "hyperparameters_list = []\n",
        "\n",
        "for b in batch_size:\n",
        "  for l in lr:\n",
        "    hyperparameters_list.append((b, l))\n",
        "    print(\"Batch size: %d, LR: %f\" % (b, l))\n",
        "    classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config)\n",
        "    train_losses, val_losses, val_acc = training_loop(classifier, train_data, val_data, l, b, NB_EPOCHS, PATIENCE, out_model_file) # train_losses, val_losses\n",
        "\n",
        "    max_accuracy = max(val_acc)\n",
        "    accuracy_list.append(max_accuracy)\n",
        "\n",
        "\n",
        "best_accuracy = max(accuracy_list)\n",
        "best_hyperparameters = hyperparameters_list[accuracy_list.index(best_accuracy)]\n",
        "print(\"Best hyperparameters: %s, accuracy: %0.4f\" % (best_hyperparameters, best_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5O5AcVWI8zE",
        "outputId": "75746c37-5b0c-4fcf-89de-266a187f26eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 32, LR: 0.000050\n",
            "Epoch 0: train loss = 1.6387, val loss = 0.8217, val acc = 0.8571\n",
            "Epoch 1: train loss = 0.8157, val loss = 0.6232, val acc = 0.8214\n",
            "Epoch 2: train loss = 0.6842, val loss = 0.5726, val acc = 0.8571\n",
            "Epoch 3: train loss = 0.6222, val loss = 0.5455, val acc = 0.8214\n",
            "Epoch 4: train loss = 0.5793, val loss = 0.5287, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.5614, val loss = 0.5180, val acc = 0.8571\n",
            "Epoch 6: train loss = 0.5337, val loss = 0.5230, val acc = 0.8571\n",
            "Epoch 7: train loss = 0.5288, val loss = 0.5111, val acc = 0.8571\n",
            "Epoch 8: train loss = 0.5077, val loss = 0.5086, val acc = 0.8214\n",
            "Epoch 9: train loss = 0.5139, val loss = 0.5163, val acc = 0.8929\n",
            "Epoch 10: train loss = 0.4910, val loss = 0.5186, val acc = 0.8929\n",
            "Early stopping at epoch 10\n",
            "Batch size: 32, LR: 0.001000\n",
            "Epoch 0: train loss = 1.6334, val loss = 0.7871, val acc = 0.9286\n",
            "Epoch 1: train loss = 0.8188, val loss = 0.6256, val acc = 0.8214\n",
            "Epoch 2: train loss = 0.6752, val loss = 0.5646, val acc = 0.8929\n",
            "Epoch 3: train loss = 0.6131, val loss = 0.5418, val acc = 0.8929\n",
            "Epoch 4: train loss = 0.5848, val loss = 0.5239, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.5557, val loss = 0.5230, val acc = 0.8571\n",
            "Epoch 6: train loss = 0.5377, val loss = 0.5124, val acc = 0.8214\n",
            "Epoch 7: train loss = 0.5220, val loss = 0.5269, val acc = 0.8214\n",
            "Epoch 8: train loss = 0.5168, val loss = 0.5198, val acc = 0.8214\n",
            "Early stopping at epoch 8\n",
            "Batch size: 32, LR: 0.005000\n",
            "Epoch 0: train loss = 1.6331, val loss = 0.8019, val acc = 0.8571\n",
            "Epoch 1: train loss = 0.8101, val loss = 0.6190, val acc = 0.8929\n",
            "Epoch 2: train loss = 0.6795, val loss = 0.5721, val acc = 0.8929\n",
            "Epoch 3: train loss = 0.6166, val loss = 0.5568, val acc = 0.8571\n",
            "Epoch 4: train loss = 0.5794, val loss = 0.5308, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.5517, val loss = 0.5221, val acc = 0.8571\n",
            "Epoch 6: train loss = 0.5345, val loss = 0.5137, val acc = 0.8929\n",
            "Epoch 7: train loss = 0.5205, val loss = 0.5075, val acc = 0.8929\n",
            "Epoch 8: train loss = 0.5075, val loss = 0.5180, val acc = 0.7857\n",
            "Epoch 9: train loss = 0.5033, val loss = 0.5082, val acc = 0.8214\n",
            "Early stopping at epoch 9\n",
            "Batch size: 64, LR: 0.000050\n",
            "Epoch 0: train loss = 1.9242, val loss = 0.9332, val acc = 0.8571\n",
            "Epoch 1: train loss = 0.9460, val loss = 0.6710, val acc = 0.8571\n",
            "Epoch 2: train loss = 0.7592, val loss = 0.5863, val acc = 0.8214\n",
            "Epoch 3: train loss = 0.6687, val loss = 0.5471, val acc = 0.8571\n",
            "Epoch 4: train loss = 0.6150, val loss = 0.5316, val acc = 0.8214\n",
            "Epoch 5: train loss = 0.5850, val loss = 0.5240, val acc = 0.7857\n",
            "Epoch 6: train loss = 0.5528, val loss = 0.5120, val acc = 0.8214\n",
            "Epoch 7: train loss = 0.5422, val loss = 0.5064, val acc = 0.8214\n",
            "Epoch 8: train loss = 0.5257, val loss = 0.4959, val acc = 0.8571\n",
            "Epoch 9: train loss = 0.5164, val loss = 0.4917, val acc = 0.8571\n",
            "Epoch 10: train loss = 0.5000, val loss = 0.4960, val acc = 0.8571\n",
            "Epoch 11: train loss = 0.4987, val loss = 0.4952, val acc = 0.8571\n",
            "Early stopping at epoch 11\n",
            "Batch size: 64, LR: 0.001000\n",
            "Epoch 0: train loss = 1.9594, val loss = 0.9509, val acc = 0.7857\n",
            "Epoch 1: train loss = 0.9349, val loss = 0.6759, val acc = 0.8571\n",
            "Epoch 2: train loss = 0.7484, val loss = 0.5964, val acc = 0.8214\n",
            "Epoch 3: train loss = 0.6663, val loss = 0.5610, val acc = 0.7857\n",
            "Epoch 4: train loss = 0.6158, val loss = 0.5376, val acc = 0.8214\n",
            "Epoch 5: train loss = 0.5791, val loss = 0.5255, val acc = 0.7857\n",
            "Epoch 6: train loss = 0.5540, val loss = 0.5118, val acc = 0.8214\n",
            "Epoch 7: train loss = 0.5419, val loss = 0.5060, val acc = 0.8214\n",
            "Epoch 8: train loss = 0.5276, val loss = 0.5042, val acc = 0.8571\n",
            "Epoch 9: train loss = 0.5134, val loss = 0.5189, val acc = 0.8214\n",
            "Epoch 10: train loss = 0.5025, val loss = 0.4980, val acc = 0.8214\n",
            "Epoch 11: train loss = 0.4948, val loss = 0.5063, val acc = 0.8571\n",
            "Epoch 12: train loss = 0.4954, val loss = 0.5016, val acc = 0.8214\n",
            "Early stopping at epoch 12\n",
            "Batch size: 64, LR: 0.005000\n",
            "Epoch 0: train loss = 1.9053, val loss = 0.9369, val acc = 0.7143\n",
            "Epoch 1: train loss = 0.9367, val loss = 0.6845, val acc = 0.7857\n",
            "Epoch 2: train loss = 0.7630, val loss = 0.5973, val acc = 0.8214\n",
            "Epoch 3: train loss = 0.6725, val loss = 0.5492, val acc = 0.8214\n",
            "Epoch 4: train loss = 0.6171, val loss = 0.5311, val acc = 0.8214\n",
            "Epoch 5: train loss = 0.5818, val loss = 0.5349, val acc = 0.8214\n",
            "Epoch 6: train loss = 0.5614, val loss = 0.5123, val acc = 0.8214\n",
            "Epoch 7: train loss = 0.5450, val loss = 0.5144, val acc = 0.8214\n",
            "Epoch 8: train loss = 0.5292, val loss = 0.5159, val acc = 0.8214\n",
            "Early stopping at epoch 8\n",
            "Batch size: 128, LR: 0.000050\n",
            "Epoch 0: train loss = 2.2781, val loss = 1.1372, val acc = 0.7500\n",
            "Epoch 1: train loss = 1.1297, val loss = 0.7687, val acc = 0.7500\n",
            "Epoch 2: train loss = 0.8551, val loss = 0.6500, val acc = 0.7857\n",
            "Epoch 3: train loss = 0.7538, val loss = 0.5933, val acc = 0.8214\n",
            "Epoch 4: train loss = 0.6915, val loss = 0.5577, val acc = 0.8214\n",
            "Epoch 5: train loss = 0.6393, val loss = 0.5396, val acc = 0.8214\n",
            "Epoch 6: train loss = 0.6096, val loss = 0.5258, val acc = 0.8214\n",
            "Epoch 7: train loss = 0.5773, val loss = 0.5116, val acc = 0.8929\n",
            "Epoch 8: train loss = 0.5578, val loss = 0.5017, val acc = 0.8214\n",
            "Epoch 9: train loss = 0.5422, val loss = 0.5022, val acc = 0.8571\n",
            "Epoch 10: train loss = 0.5295, val loss = 0.5006, val acc = 0.8571\n",
            "Epoch 11: train loss = 0.5157, val loss = 0.4980, val acc = 0.8571\n",
            "Epoch 12: train loss = 0.5141, val loss = 0.4945, val acc = 0.8571\n",
            "Epoch 13: train loss = 0.5025, val loss = 0.4861, val acc = 0.8571\n",
            "Epoch 14: train loss = 0.4917, val loss = 0.4940, val acc = 0.8571\n",
            "Epoch 15: train loss = 0.4887, val loss = 0.4968, val acc = 0.8571\n",
            "Early stopping at epoch 15\n",
            "Batch size: 128, LR: 0.001000\n",
            "Epoch 0: train loss = 2.3037, val loss = 1.1421, val acc = 0.7500\n",
            "Epoch 1: train loss = 1.1191, val loss = 0.7828, val acc = 0.7857\n",
            "Epoch 2: train loss = 0.8611, val loss = 0.6590, val acc = 0.7857\n",
            "Epoch 3: train loss = 0.7477, val loss = 0.5969, val acc = 0.8214\n",
            "Epoch 4: train loss = 0.6855, val loss = 0.5642, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.6378, val loss = 0.5416, val acc = 0.8571\n",
            "Epoch 6: train loss = 0.6069, val loss = 0.5395, val acc = 0.8214\n",
            "Epoch 7: train loss = 0.5813, val loss = 0.5195, val acc = 0.8214\n",
            "Epoch 8: train loss = 0.5559, val loss = 0.5191, val acc = 0.8214\n",
            "Epoch 9: train loss = 0.5436, val loss = 0.5059, val acc = 0.8214\n",
            "Epoch 10: train loss = 0.5316, val loss = 0.5065, val acc = 0.8214\n",
            "Epoch 11: train loss = 0.5190, val loss = 0.4918, val acc = 0.8571\n",
            "Epoch 12: train loss = 0.5127, val loss = 0.4916, val acc = 0.8214\n",
            "Epoch 13: train loss = 0.5005, val loss = 0.4880, val acc = 0.7857\n",
            "Epoch 14: train loss = 0.4967, val loss = 0.4856, val acc = 0.8214\n",
            "Epoch 15: train loss = 0.4879, val loss = 0.4878, val acc = 0.7857\n",
            "Epoch 16: train loss = 0.4852, val loss = 0.4836, val acc = 0.8571\n",
            "Epoch 17: train loss = 0.4793, val loss = 0.4836, val acc = 0.8214\n",
            "Epoch 18: train loss = 0.4642, val loss = 0.4842, val acc = 0.8571\n",
            "Early stopping at epoch 18\n",
            "Batch size: 128, LR: 0.005000\n",
            "Epoch 0: train loss = 2.3063, val loss = 1.1383, val acc = 0.8214\n",
            "Epoch 1: train loss = 1.1231, val loss = 0.7885, val acc = 0.8214\n",
            "Epoch 2: train loss = 0.8709, val loss = 0.6564, val acc = 0.8214\n",
            "Epoch 3: train loss = 0.7436, val loss = 0.6112, val acc = 0.8571\n",
            "Epoch 4: train loss = 0.6842, val loss = 0.5681, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.6426, val loss = 0.5451, val acc = 0.8214\n",
            "Epoch 6: train loss = 0.6064, val loss = 0.5283, val acc = 0.8214\n",
            "Epoch 7: train loss = 0.5868, val loss = 0.5174, val acc = 0.8214\n",
            "Epoch 8: train loss = 0.5637, val loss = 0.5060, val acc = 0.8929\n",
            "Epoch 9: train loss = 0.5403, val loss = 0.5016, val acc = 0.8571\n",
            "Epoch 10: train loss = 0.5346, val loss = 0.4962, val acc = 0.8214\n",
            "Epoch 11: train loss = 0.5172, val loss = 0.4985, val acc = 0.7857\n",
            "Epoch 12: train loss = 0.5082, val loss = 0.5043, val acc = 0.7857\n",
            "Early stopping at epoch 12\n",
            "Best hyperparameters: (32, 0.001), accuracy: 0.9286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config)\n",
        "train_losses, val_losses, val_acc = training_loop(best_classifier, train_data, val_data, 0.001, 32, NB_EPOCHS, PATIENCE, out_model_file) # train_losses, val_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51AmB-jxzzZr",
        "outputId": "07d0c262-088c-4193-868a-20ddca38250d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss = 1.6184, val loss = 0.8179, val acc = 0.8929\n",
            "Epoch 1: train loss = 0.8055, val loss = 0.6178, val acc = 0.8571\n",
            "Epoch 2: train loss = 0.6815, val loss = 0.5719, val acc = 0.8571\n",
            "Epoch 3: train loss = 0.6198, val loss = 0.5364, val acc = 0.8214\n",
            "Epoch 4: train loss = 0.5788, val loss = 0.5238, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.5560, val loss = 0.5326, val acc = 0.8214\n",
            "Epoch 6: train loss = 0.5336, val loss = 0.5229, val acc = 0.8571\n",
            "Epoch 7: train loss = 0.5243, val loss = 0.5104, val acc = 0.8571\n",
            "Epoch 8: train loss = 0.5174, val loss = 0.5187, val acc = 0.8214\n",
            "Epoch 9: train loss = 0.5124, val loss = 0.5163, val acc = 0.8214\n",
            "Early stopping at epoch 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph to visualize losses\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses, label='loss on train')\n",
        "plt.plot(val_losses, label='loss on val')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Learning curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ltjJwfTfIYlR",
        "outputId": "838569ff-e83f-403f-ea3b-4b28e97d90f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHt6rTougG0K"
      },
      "source": [
        "### TODO7: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHYxcJBNexzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802ea2d1-32c0-4094-af7d-769d41480f29"
      },
      "source": [
        "# TODO HERE : run on dev and evaluate\n",
        "\n",
        "best_classifier.eval()\n",
        "pred_labels, gold_labels = best_classifier.run_on_dataset(test_data, batch_size=32)\n",
        "\n",
        "accuracy = 0\n",
        "\n",
        "for gold, pred in zip(gold_labels, pred_labels):\n",
        "    accuracy += best_classifier.evaluate(gold, pred)\n",
        "\n",
        "avg_accuracy = accuracy / len(gold_labels)\n",
        "\n",
        "print(f\"Accuracy on the test set: {avg_accuracy:.4f} in frozen mode.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.8415 in frozen mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters search in fine-tuning\n",
        "batch_size = [32, 64, 128]\n",
        "lr = [0.00005, 0.001, 0.005]\n",
        "\n",
        "accuracy_list = []\n",
        "hyperparameters_list = []\n",
        "\n",
        "for b in batch_size:\n",
        "  for l in lr:\n",
        "    hyperparameters_list.append((b, l))\n",
        "    print(\"Batch size: %d, LR: %f\" % (b, l))\n",
        "    classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config, freeze_bert = False)\n",
        "    train_losses, val_losses, val_acc = training_loop(classifier, train_data, val_data, l, b, NB_EPOCHS, PATIENCE, out_model_file) # train_losses, val_losses\n",
        "\n",
        "    max_accuracy = max(val_acc)\n",
        "    accuracy_list.append(max_accuracy)\n",
        "\n",
        "\n",
        "best_accuracy_ft = max(accuracy_list)\n",
        "best_hyperparameters_ft = hyperparameters_list[accuracy_list.index(best_accuracy_ft)]\n",
        "print(\"Best hyperparameters : %s, Best accuracy : %0.4f\" % (best_hyperparameters_ft, best_accuracy_ft))"
      ],
      "metadata": {
        "id": "0i1-WWwJ7n3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run on dev and evaluate in fine-tuning mode\n",
        "\n",
        "best_classifier_ft = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config, freeze_bert = False)\n",
        "train_losses, val_losses, val_acc = training_loop(best_classifier_ft, train_data, val_data, 0.001, 128, NB_EPOCHS, PATIENCE, out_model_file) # train_losses, val_losses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6QSP9Zu6snM",
        "outputId": "5098b831-81fa-4a32-b89b-51c098da13d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss = 2.3253, val loss = 1.1468, val acc = 0.8214\n",
            "Epoch 1: train loss = 1.1223, val loss = 0.7643, val acc = 0.8571\n",
            "Epoch 2: train loss = 0.8667, val loss = 0.6533, val acc = 0.8214\n",
            "Epoch 3: train loss = 0.7539, val loss = 0.5964, val acc = 0.8571\n",
            "Epoch 4: train loss = 0.6878, val loss = 0.5656, val acc = 0.8571\n",
            "Epoch 5: train loss = 0.6426, val loss = 0.5380, val acc = 0.8571\n",
            "Epoch 6: train loss = 0.5989, val loss = 0.5280, val acc = 0.8929\n",
            "Epoch 7: train loss = 0.5765, val loss = 0.5191, val acc = 0.8571\n",
            "Epoch 8: train loss = 0.5655, val loss = 0.5157, val acc = 0.8571\n",
            "Epoch 9: train loss = 0.5470, val loss = 0.5034, val acc = 0.8214\n",
            "Epoch 10: train loss = 0.5268, val loss = 0.5000, val acc = 0.8571\n",
            "Epoch 11: train loss = 0.5193, val loss = 0.4984, val acc = 0.8571\n",
            "Epoch 12: train loss = 0.5068, val loss = 0.4905, val acc = 0.8929\n",
            "Epoch 13: train loss = 0.5032, val loss = 0.4835, val acc = 0.8929\n",
            "Epoch 14: train loss = 0.4954, val loss = 0.4887, val acc = 0.8571\n",
            "Epoch 15: train loss = 0.4840, val loss = 0.4789, val acc = 0.8929\n",
            "Epoch 16: train loss = 0.4816, val loss = 0.4807, val acc = 0.8571\n",
            "Epoch 17: train loss = 0.4761, val loss = 0.4942, val acc = 0.8571\n",
            "Early stopping at epoch 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_classifier_ft.eval()\n",
        "pred_labels, gold_labels = best_classifier_ft.run_on_dataset(test_data, batch_size=32)\n",
        "\n",
        "accuracy = 0\n",
        "\n",
        "for gold, pred in zip(gold_labels, pred_labels):\n",
        "    accuracy += best_classifier_ft.evaluate(gold, pred)\n",
        "\n",
        "avg_accuracy = accuracy / len(gold_labels)\n",
        "\n",
        "print(f\"Accuracy on the test set: {avg_accuracy:.4f} in fine-tuning mode.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b832DTnUQ6IQ",
        "outputId": "30d2e144-4667-4bbb-f5d4-5800e18b0ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 0.8496 in fine-tuning mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale (\"barème\")\n",
        "\n",
        "- basic system will give 12 points\n",
        "\n",
        "- quality of code / comments = 2 points\n",
        "\n",
        "\n",
        "- various additional points (to choose)\n",
        "\n",
        "  - generalization analysis\n",
        "   Do you think it would be better to predict seen-in-train lemma/frame associations only ?\n",
        "   (in order to answer that question, propose and implement simple analysis of the predictions performed without any control of the frame/lemma association)\n",
        "\n",
        "  - implement an option to only predict seen-in-train lemma/frame associations\n",
        "\n",
        "  - nice hyperparameter search\n",
        "\n",
        "  - high results thanks to nice hyperparameter search\n",
        "\n",
        "  - implement early stopping\n",
        "\n",
        "  - does it help to fine-tune with a MLP instead of single layer ?\n",
        "\n",
        "  - does it help to use a concatenation of flaubert's embeddings at different layers instead of the last layer only (eg 4 last layers, cf. table 7 of devlin et al. 2019) (do this in frozen mode only)\n",
        "\n",
        "  - does it help to add a lemma embedding of the target (concatenate it to the bert output, before final linear layer)?\n",
        "\n",
        "  - ... other ideas are welcome ...\n",
        "\n",
        "Approximate expected accuracy:\n",
        " - In frozen mode, basic system can reach 83 / 84 % on the dev set when well trained\n",
        "\n",
        " - In fine-tuning mode: results seem unstable\n",
        "  - take care to search for an appropriate learning rate, which tends to be lower than in frozen mode\n",
        "  - some of the runs get stuck at 37% of accuracy, corresponding to assigning the MFS to all the instances (\"other_sense\" frame)\n",
        "  - when learning goes well, accuracy can reach 88, or even 90% for some runs\n",
        "\n",
        "\n",
        "NB: write below what you chose to investigate / implement.\n",
        "Summarize your results / hyper-parameter search.\n",
        "For an extra feature to count, you need to write down an analysis of the results.\n",
        "\n",
        "Your notebook should show traces of a complete training and evaluation phase."
      ],
      "metadata": {
        "id": "Y6CDdnT5qXHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion"
      ],
      "metadata": {
        "id": "zcdoiVeI0ju7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "I've implemented early stopping in the `training_loop` function of the training loop, if the validation loss does not improve for 2 epochs, the training is stopped. And it seems to work well for the frozen model and the fine-tuned model.  \n",
        "\n",
        "Also, i've done the hyperparameter search in both modes. For the frozen mode, the learning rate is set to 0.001 and the batch size is set to 32. For the fine-tuning mode, the learning rate is set to the same value as in the frozen mode and the batch size is set to 128.\n",
        "\n",
        "Finally, from the graph and the results of evaluation, i've found that the fine-tuning mode is slightly better than the frozen mode. But both of them can reach 84% on the test set.\n",
        "\n",
        "\\#@@ very good"
      ],
      "metadata": {
        "id": "k8EF8McJxAF9"
      }
    }
  ]
}